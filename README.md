# zhihu
用scrapy框架爬取知乎用户信息
分析知乎网页的结构-->需要添加的必要头部信息-->编写代码
第一次没有添加停顿，爬到9000+多条的时候就被网站封了，就添加了一个随机的User-Agent，并添加了停顿。爬取速度是慢了一点，但相对稳定一些。
